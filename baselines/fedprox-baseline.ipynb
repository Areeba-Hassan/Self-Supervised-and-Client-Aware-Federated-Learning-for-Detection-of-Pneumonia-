{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7773,"sourceType":"datasetVersion","datasetId":4667},{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810},{"sourceId":2169393,"sourceType":"datasetVersion","datasetId":1302315},{"sourceId":3324348,"sourceType":"datasetVersion","datasetId":576013}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# --- Imports ---\nimport os\nimport sys\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport random\nimport copy\nfrom tqdm.auto import tqdm \nimport warnings\nimport torch.optim as optim\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\nwarnings.filterwarnings('ignore', category=UserWarning)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-03T16:42:22.028672Z","iopub.execute_input":"2025-12-03T16:42:22.028991Z","iopub.status.idle":"2025-12-03T16:42:33.266119Z","shell.execute_reply.started":"2025-12-03T16:42:22.028967Z","shell.execute_reply":"2025-12-03T16:42:33.265514Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"#Suppress warnings\nwarnings.filterwarnings('ignore', category=UserWarning)\nwarnings.filterwarnings('ignore', message='.*can only test a child process.*')\nos.environ['PYTHONWARNINGS'] = 'ignore'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T17:08:36.123826Z","iopub.execute_input":"2025-12-03T17:08:36.124114Z","iopub.status.idle":"2025-12-03T17:08:36.128589Z","shell.execute_reply.started":"2025-12-03T17:08:36.124091Z","shell.execute_reply":"2025-12-03T17:08:36.127847Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# --- Device and Global Constants ---\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nIMG_SIZE = 224\nPATCH_SIZE = 16\nclients = 5 \nprint(f\"Imports and Constants defined. Training on: {DEVICE}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T17:08:57.624199Z","iopub.execute_input":"2025-12-03T17:08:57.624899Z","iopub.status.idle":"2025-12-03T17:08:57.710971Z","shell.execute_reply.started":"2025-12-03T17:08:57.624869Z","shell.execute_reply":"2025-12-03T17:08:57.710314Z"}},"outputs":[{"name":"stdout","text":"Imports and Constants defined. Training on: cuda\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#manually loading the four datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-02T16:52:28.244700Z","iopub.execute_input":"2025-12-02T16:52:28.245292Z","iopub.status.idle":"2025-12-02T16:52:28.254425Z","shell.execute_reply.started":"2025-12-02T16:52:28.245272Z","shell.execute_reply":"2025-12-02T16:52:28.253688Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#checking directory structures\n\nprint(\"--- Inspecting /kaggle/input/ ---\")\nfor dirname in os.listdir(\"/kaggle/input\"):\n    print(f\"\\n--- CONTENTS OF: {dirname} ---\")\n    \n    # Check if it's a directory before listing contents\n    dir_path = os.path.join(\"/kaggle/input\", dirname)\n    if os.path.isdir(dir_path):\n        # List the top 5 items and check for common subdirectories\n        try:\n            items = os.listdir(dir_path)\n            for item in items[:5]:\n                print(f\"  - {item}\")\n        except Exception as e:\n            print(f\"  - Error listing directory: {e}\")\n\nprint(\"\\n--- END OF INSPECTION ---\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T17:09:02.044865Z","iopub.execute_input":"2025-12-03T17:09:02.045544Z","iopub.status.idle":"2025-12-03T17:09:02.072719Z","shell.execute_reply.started":"2025-12-03T17:09:02.045520Z","shell.execute_reply":"2025-12-03T17:09:02.071998Z"}},"outputs":[{"name":"stdout","text":"--- Inspecting /kaggle/input/ ---\n\n--- CONTENTS OF: chest-xray-pneumonia ---\n  - chest_xray\n\n--- CONTENTS OF: sample ---\n  - sample_labels.csv\n  - sample\n\n--- CONTENTS OF: covid19-radiography-database ---\n  - COVID-19_Radiography_Dataset\n\n--- CONTENTS OF: chexpert ---\n  - valid.csv\n  - valid\n  - train.csv\n  - train\n\n--- END OF INSPECTION ---\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"\n# --- Kaggle Data Paths ---\n# chest-xray-pneumonia (paultimothymooney)\nPNEU_DIR = \"/kaggle/input/chest-xray-pneumonia/chest_xray\" # Source: PNEU\n\n# nih-chest-xrays/sample (nih-chest-xrays)\nNIH_SAMPLE_DIR = \"/kaggle/input/sample\" # Source: NIH\n\n#COVID-19 Radiography Database (tawsifurrahman)\nCOVID19_DIR = \"/kaggle/input/covid19-radiography-database/COVID-19_Radiography_Dataset\" # Source: COVID\n\n#CheXpert\nCHEXPERT_DIR = \"/kaggle/input/chexpert\" # Source: CHEXP","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T17:09:04.683198Z","iopub.execute_input":"2025-12-03T17:09:04.683986Z","iopub.status.idle":"2025-12-03T17:09:04.687444Z","shell.execute_reply.started":"2025-12-03T17:09:04.683957Z","shell.execute_reply":"2025-12-03T17:09:04.686846Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#NIH Folder Inspection\n\nNIH_SAMPLE_DIR = \"/kaggle/input/sample\"\nIMAGE_BASE_DIR = os.path.join(NIH_SAMPLE_DIR, \"sample\", \"sample\", \"images\")\n\nprint(f\"Inspecting assumed image path: {IMAGE_BASE_DIR}\")\n\nif os.path.exists(IMAGE_BASE_DIR):\n    #List the first 5 files found in the directory\n    image_files = [f for f in os.listdir(IMAGE_BASE_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n    \n    if image_files:\n        print(f\"Found {len(image_files)} image files. First 5 are:\")\n        for f in image_files[:5]:\n            print(f\"  - {f}\")\n    else:\n        print(\"Folder exists, but no image files (png/jpg/jpeg) were found inside.\")\nelse:\n    print(\"Image folder path DOES NOT exist.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T17:09:07.997392Z","iopub.execute_input":"2025-12-03T17:09:07.997973Z","iopub.status.idle":"2025-12-03T17:09:08.085061Z","shell.execute_reply.started":"2025-12-03T17:09:07.997948Z","shell.execute_reply":"2025-12-03T17:09:08.084478Z"}},"outputs":[{"name":"stdout","text":"Inspecting assumed image path: /kaggle/input/sample/sample/sample/images\nFound 5606 image files. First 5 are:\n  - 00006199_010.png\n  - 00003503_000.png\n  - 00017423_004.png\n  - 00022830_001.png\n  - 00016794_000.png\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#CheXpert CSV Path Inspection\n\nCHEXPERT_DIR = \"/kaggle/input/chexpert\"\nCSV_PATH = os.path.join(CHEXPERT_DIR, \"train.csv\")\n\nif os.path.exists(CSV_PATH):\n    print(f\"Loading CSV from: {CSV_PATH}\")\n    df_sample = pd.read_csv(CSV_PATH, nrows=5)\n    \n    #Print the first 5 entries of the Path column\n    if 'Path' in df_sample.columns:\n        print(\"\\nFirst 5 entries in the 'Path' column:\")\n        for path in df_sample['Path']:\n            print(f\" - {path}\")\n    else:\n        print(\"Error: 'Path' column not found in train.csv.\")\nelse:\n    print(f\"Error: train.csv not found at {CSV_PATH}. Cannot inspect.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T17:09:11.215275Z","iopub.execute_input":"2025-12-03T17:09:11.215941Z","iopub.status.idle":"2025-12-03T17:09:11.224353Z","shell.execute_reply.started":"2025-12-03T17:09:11.215914Z","shell.execute_reply":"2025-12-03T17:09:11.223605Z"}},"outputs":[{"name":"stdout","text":"Loading CSV from: /kaggle/input/chexpert/train.csv\n\nFirst 5 entries in the 'Path' column:\n - CheXpert-v1.0-small/train/patient00001/study1/view1_frontal.jpg\n - CheXpert-v1.0-small/train/patient00002/study2/view1_frontal.jpg\n - CheXpert-v1.0-small/train/patient00002/study1/view1_frontal.jpg\n - CheXpert-v1.0-small/train/patient00002/study1/view2_lateral.jpg\n - CheXpert-v1.0-small/train/patient00003/study1/view1_frontal.jpg\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"#Initialize list of DataFrames\ndata_frames = []\n\n#Loading Functions\n\ndef load_pneumonia_all_splits(base_dir):\n    records = []\n    for split in [\"train\", \"val\", \"test\"]:\n        for label in [\"PNEUMONIA\", \"NORMAL\"]:\n            folder = os.path.join(base_dir, split, label)\n            if os.path.exists(folder):\n                for fname in os.listdir(folder):\n                    if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n                        records.append({\n                            \"path\": os.path.join(folder, fname),\n                            \"label\": \"pneumonia\" if label == \"PNEUMONIA\" else \"normal\",\n                            \"source\": \"PNEU\" \n                        })\n    return pd.DataFrame(records)\n\ndef load_nih(base_dir):\n    \n    csv_path = os.path.join(base_dir, \"sample_labels.csv\")\n    if not os.path.exists(csv_path):\n        raise FileNotFoundError(f\"NIH CSV not found at: {csv_path}\")\n        \n    df = pd.read_csv(csv_path)\n    records = []\n    \n    IMAGE_BASE_DIR = os.path.join(base_dir, \"sample\", \"sample\", \"images\")\n    print(f\"DEBUG: NIH Image search path: {IMAGE_BASE_DIR}\")\n    \n    if not os.path.exists(IMAGE_BASE_DIR):\n         raise FileNotFoundError(f\"NIH Image folder not found at: {IMAGE_BASE_DIR}\")\n\n    for idx, row in df.iterrows():\n        image_id = row['Image Index']\n        #Image path: /kaggle/input/sample/sample/sample/images/[image_id]\n        img_path = os.path.join(IMAGE_BASE_DIR, image_id)\n        \n        if os.path.exists(img_path):\n            label = \"pneumonia\" if \"Pneumonia\" in str(row['Finding Labels']) else \"normal\"\n            records.append({\"path\": img_path, \"label\": label, \"source\": \"NIH\"}) \n            \n    return pd.DataFrame(records)\n\n\ndef load_chexpert_all(chexpert_dir):\n    \n    records = []\n    PREFIX_FOLDER = \"CheXpert-v1.0-small\"\n    IMAGE_ROOT = chexpert_dir \n    \n    print(f\"DEBUG: CheXpert Image Root assumed to be: {IMAGE_ROOT}\")\n\n    for csv_name in [\"train.csv\", \"valid.csv\"]:\n        csv_path = os.path.join(chexpert_dir, csv_name)\n        \n        if not os.path.exists(csv_path):\n             print(f\"Missing CSV: {csv_name}. Skipping.\")\n             continue\n\n        df = pd.read_csv(csv_path)\n        print(f\"DEBUG: Processing {csv_name} with {len(df)} entries...\")\n        \n        valid_path_starts = {\"train/\", \"valid/\"}\n\n        for idx, row in df.iterrows():\n            img_rel = row[\"Path\"].replace(\"\\\\\", \"/\") \n\n            relative_path = img_rel\n            \n            #Strip the known prefix\n            if img_rel.startswith(PREFIX_FOLDER + \"/\"):\n                relative_path = img_rel[len(PREFIX_FOLDER + \"/\"):]\n\n            #Check if the resulting path is a valid image container path\n            if not any(relative_path.startswith(s) for s in valid_path_starts):\n                continue\n                \n            #Construct final path: /kaggle/input/chexpert/train/patient...\n            img_path = os.path.join(IMAGE_ROOT, relative_path)\n\n            if not os.path.exists(img_path):\n                 continue\n\n            label = \"pneumonia\" if row.get(\"Pneumonia\", 0) == 1.0 else \"normal\"\n\n            records.append({\n                \"path\": img_path,\n                \"label\": label,\n                \"source\": \"CHEXP\" \n            })\n            \n            #Check for the first successful load and print its path for verification\n            if len(records) == 1:\n                print(f\"DEBUG: First successful CheXpert path found: {img_path}\")\n\n\n    return pd.DataFrame(records)\n\n\ndef load_covid19(base_dir):\n    records = []\n    label_map = {\"COVID\": \"pneumonia\", \"Viral Pneumonia\": \"pneumonia\", \"Normal\": \"normal\"}\n    for folder, label in label_map.items():\n        class_folder = os.path.join(base_dir, folder, \"images\")\n        if os.path.exists(class_folder):\n            for fname in os.listdir(class_folder):\n                if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n                    records.append({\"path\": os.path.join(class_folder, fname), \"label\": label, \"source\": \"COVID\"}) \n    return pd.DataFrame(records)\n\nprint(\"All common functions defined.\")\n\n#Load PNEUMONIA Data\ntry:\n    pneu_df = load_pneumonia_all_splits(PNEU_DIR)\n    print(f\"PNEU loaded: {len(pneu_df)}\")\n    data_frames.append(pneu_df)\nexcept Exception as e:\n    print(f\"PNEUMONIA Load Failed: {e}\")\n    pneu_df = pd.DataFrame()\n\n#Load NIH Data\ntry:\n    nih_df = load_nih(NIH_SAMPLE_DIR)\n    print(f\"NIH Sample loaded: {len(nih_df)}\")\n    data_frames.append(nih_df)\nexcept FileNotFoundError as e:\n    print(f\"NIH Load Failed: {e}\")\n    nih_df = pd.DataFrame()\nexcept Exception as e:\n    print(f\"NIH Load Failed: General error: {e}\")\n    nih_df = pd.DataFrame()\n\n#Load COVID-19 Data\ntry:\n    covid_df = load_covid19(COVID19_DIR)\n    print(f\"COVID-19 loaded: {len(covid_df)}\")\n    data_frames.append(covid_df)\nexcept Exception as e:\n    print(f\"COVID-19 Load Failed: {e}\")\n    covid_df = pd.DataFrame()\n\n#Load CheXpert Data\ntry:\n    chexpert_df = load_chexpert_all(CHEXPERT_DIR)\n    print(f\"CheXpert loaded: {len(chexpert_df)}\")\n    data_frames.append(chexpert_df)\nexcept Exception as e:\n    print(f\"CheXpert Load Failed: {e}\")\n    chexpert_df = pd.DataFrame()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T17:09:19.889315Z","iopub.execute_input":"2025-12-03T17:09:19.889630Z","iopub.status.idle":"2025-12-03T17:25:02.915145Z","shell.execute_reply.started":"2025-12-03T17:09:19.889606Z","shell.execute_reply":"2025-12-03T17:25:02.914499Z"}},"outputs":[{"name":"stdout","text":"All common functions defined.\nPNEU loaded: 5856\nDEBUG: NIH Image search path: /kaggle/input/sample/sample/sample/images\nNIH Sample loaded: 5606\nCOVID-19 loaded: 15153\nDEBUG: CheXpert Image Root assumed to be: /kaggle/input/chexpert\nDEBUG: Processing train.csv with 223414 entries...\nDEBUG: First successful CheXpert path found: /kaggle/input/chexpert/train/patient00001/study1/view1_frontal.jpg\nDEBUG: Processing valid.csv with 234 entries...\nCheXpert loaded: 223648\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"#Merge and Finalize DataFrames\n\n#merging\nmerged_df = pd.concat([pneu_df,nih_df,covid_df,chexpert_df], ignore_index=True)\nmerged_df = merged_df[merged_df['path'].apply(os.path.exists)]\nmerged_df = merged_df.drop_duplicates(subset=\"path\")\nmerged_df = merged_df.sample(frac=1, random_state=42).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T17:41:18.969521Z","iopub.execute_input":"2025-12-03T17:41:18.969758Z","iopub.status.idle":"2025-12-03T17:45:23.888805Z","shell.execute_reply.started":"2025-12-03T17:41:18.969741Z","shell.execute_reply":"2025-12-03T17:45:23.888023Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"#Label Encoding\nlabel_mapping = {\"normal\": 0, \"pneumonia\": 1}\nmerged_df['label_id'] = merged_df['label'].map(label_mapping)\n\nprint(\"\\n--- Baseline Dataset Statistics ---\")\nprint(f\"Total images after cleaning: {len(merged_df)}\")\nif not merged_df.empty:\n        print(f\"Pneumonia ratio: {merged_df['label_id'].mean()*100:.2f}%\")\n        print(f\"Sources included: {merged_df['source'].unique().tolist()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T17:45:43.002541Z","iopub.execute_input":"2025-12-03T17:45:43.003109Z","iopub.status.idle":"2025-12-03T17:45:43.030076Z","shell.execute_reply.started":"2025-12-03T17:45:43.003086Z","shell.execute_reply":"2025-12-03T17:45:43.029512Z"}},"outputs":[{"name":"stdout","text":"\n--- Baseline Dataset Statistics ---\nTotal images after cleaning: 250263\nPneumonia ratio: 6.13%\nSources included: ['CHEXP', 'COVID', 'PNEU', 'NIH']\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"#Subsampling normal class for balance\n\n#Separate the classes\npneumonia_df = merged_df[merged_df['label_id'] == 1].copy()\nnormal_df = merged_df[merged_df['label_id'] == 0].copy()\n\ntarget_normal_count = int(len(pneumonia_df) * 1.75)\n\n#Subsample normal data\nif len(normal_df) > target_normal_count:\n    subsampled_normal_df = normal_df.sample(n=target_normal_count, random_state=42)\nelse:\n    #If the current normal count is alr low, use all of it\n    subsampled_normal_df = normal_df\n\n#Combine full pneumonia set with the subsampled normal set\nbalanced_df = pd.concat([pneumonia_df, subsampled_normal_df]).sample(frac=1, random_state=42).reset_index(drop=True)\n\nprint(\"\\n--- Balanced Dataset Statistics ---\")\nprint(f\"Total images after balancing: {len(balanced_df)}\")\nif not balanced_df.empty:\n    pneu_ratio = balanced_df['label_id'].mean() * 100\n    print(f\"Pneumonia ratio: {pneu_ratio:.2f}%\")\n    print(f\"Sources included: {balanced_df['source'].unique().tolist()}\")\nprint(\"--------------------------\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T17:45:46.623589Z","iopub.execute_input":"2025-12-03T17:45:46.624258Z","iopub.status.idle":"2025-12-03T17:45:46.678968Z","shell.execute_reply.started":"2025-12-03T17:45:46.624235Z","shell.execute_reply":"2025-12-03T17:45:46.678222Z"}},"outputs":[{"name":"stdout","text":"\n--- Balanced Dataset Statistics ---\nTotal images after balancing: 42193\nPneumonia ratio: 36.36%\nSources included: ['CHEXP', 'COVID', 'PNEU', 'NIH']\n--------------------------\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"#detailed stats\n#Overall Class Balance (Label Heterogeneity)\nlabel_counts = balanced_df['label'].value_counts(normalize=True) * 100\nprint(\"\\n1. Overall Label Distribution (Pneumonia vs. Normal):\")\nprint(label_counts)\n\n#Source Distribution (Source Heterogeneity)\nsource_counts = balanced_df['source'].value_counts(normalize=True) * 100\nprint(\"\\n2. Source Distribution Across All Data:\")\nprint(source_counts)\n\n#Source-Label (Non-IID measure)\nnon_iid = pd.crosstab(balanced_df['source'], balanced_df['label'], normalize='index') * 100\nprint(\"\\n3. Label Distribution (Class Balance) within each Source:\")\nprint(non_iid)\nprint(\"--------------------------\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T17:45:49.254803Z","iopub.execute_input":"2025-12-03T17:45:49.255076Z","iopub.status.idle":"2025-12-03T17:45:49.293498Z","shell.execute_reply.started":"2025-12-03T17:45:49.255054Z","shell.execute_reply":"2025-12-03T17:45:49.292772Z"}},"outputs":[{"name":"stdout","text":"\n1. Overall Label Distribution (Pneumonia vs. Normal):\nlabel\nnormal       63.636148\npneumonia    36.363852\nName: proportion, dtype: float64\n\n2. Source Distribution Across All Data:\nsource\nCHEXP    73.320219\nCOVID    14.526106\nPNEU     10.537293\nNIH       1.616382\nName: proportion, dtype: float64\n\n3. Label Distribution (Class Balance) within each Source:\nlabel      normal  pneumonia\nsource                      \nCHEXP   80.453194  19.546806\nCOVID   19.056942  80.943058\nNIH     90.909091   9.090909\nPNEU     3.891138  96.108862\n--------------------------\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"# **Global Split**","metadata":{}},{"cell_type":"code","source":"#Creating global test set\n\ndef create_global_test_set(balanced_df, test_size=0.15, random_state=42):\n\n    #Split stratified by label\n    train_val_df, test_df = train_test_split(\n        balanced_df,\n        test_size=test_size,\n        stratify=balanced_df['label_id'],\n        random_state=random_state\n    )\n    \n    print(f\"\\n{'='*60}\")\n    print(\"GLOBAL TEST SET CREATION (STEP 1)\")\n    print(f\"{'='*60}\")\n    print(f\"Total samples: {len(balanced_df)}\")\n    print(f\"Remaining for clients: {len(train_val_df)} ({len(train_val_df)/len(balanced_df)*100:.1f}%)\")\n    print(f\"Global Test (HELD OUT): {len(test_df)} ({len(test_df)/len(balanced_df)*100:.1f}%)\")\n    print(f\"Test pneumonia ratio: {test_df['label_id'].mean()*100:.1f}%\")\n    print(f\"Test source distribution:\")\n    print(test_df['source'].value_counts())\n    print(f\"{'='*60}\\n\")\n    \n    return train_val_df, test_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T17:45:53.001783Z","iopub.execute_input":"2025-12-03T17:45:53.002033Z","iopub.status.idle":"2025-12-03T17:45:53.007227Z","shell.execute_reply.started":"2025-12-03T17:45:53.002017Z","shell.execute_reply":"2025-12-03T17:45:53.006388Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"train_val_df, global_test_df = create_global_test_set(balanced_df, test_size=0.15)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T17:45:55.571759Z","iopub.execute_input":"2025-12-03T17:45:55.572301Z","iopub.status.idle":"2025-12-03T17:45:55.598274Z","shell.execute_reply.started":"2025-12-03T17:45:55.572275Z","shell.execute_reply":"2025-12-03T17:45:55.597737Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nGLOBAL TEST SET CREATION (STEP 1)\n============================================================\nTotal samples: 42193\nRemaining for clients: 35864 (85.0%)\nGlobal Test (HELD OUT): 6329 (15.0%)\nTest pneumonia ratio: 36.4%\nTest source distribution:\nsource\nCHEXP    4622\nCOVID     950\nPNEU      649\nNIH       108\nName: count, dtype: int64\n============================================================\n\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# **CLIENT SPLIT**","metadata":{}},{"cell_type":"code","source":"##Client Split\n\nVAL_FRACTION = 0.30\nFL_TRAIN_FRACTION = 0.65\n\nsource_map = ['CHEXP', 'COVID', 'NIH', 'PNEU'] \nsource_allocation_matrix = np.array([\n    # CHEXP | COVID | NIH | PNEU \n    [0.15,   0.05,   0.45,  0.35], # Client 0: NIH heavy\n    [0.35,   0.10,   0.10,  0.30], # Client 1: CHEXP heavy\n    [0.15,   0.40,   0.15,  0.30], # Client 2: COVID heavy\n    [0.20,   0.15,   0.15,  0.50], # Client 3: PNEU heavy\n    [0.25,   0.20,   0.25,  0.30]  # Client 4: Balanced skew\n])\n\nTARGET_SAMPLES_PER_CLIENT = 3000 \n\n\ndef split_client_data_stratified(client_df, val_frac, fl_train_frac):\n    \"\"\"Splits a client's data into FL Train and Validation subsets.\"\"\"\n    \n    #Check if stratification is possible\n    stratify_target = None\n    pneu_count = client_df['label_id'].sum()\n    if pneu_count > 0 and (len(client_df) - pneu_count) > 0:\n        stratify_target = client_df['label_id']\n    \n    #Separate Validation\n    train_val_df, val_df = train_test_split(client_df, test_size=val_frac, \n                                            stratify=stratify_target, random_state=42)\n    \n    stratify_target_train = None\n    pneu_count_train = train_val_df['label_id'].sum()\n    if pneu_count_train > 0 and (len(train_val_df) - pneu_count_train) > 0:\n        stratify_target_train = train_val_df['label_id']\n    \n    #Separate FL Train \n    fl_train_relative_size = FL_TRAIN_FRACTION / max(1e-6, (1 - VAL_FRACTION))\n    fl_train_relative_size = min(0.99, fl_train_relative_size)\n\n    _temp_ssl_df, fl_train_df = train_test_split(train_val_df, test_size=relative_test_size, \n                                                 stratify=stratify_target_train, random_state=42)\n    \n    #The remaining data is the Labeled SSL set\n    ssl_labeled_df = _temp_ssl_df\n\n    return {\n        'fl_train': fl_train_df.reset_index(drop=True),\n        'val': val_df.reset_index(drop=True),\n        'ssl_labeled': ssl_labeled_df.reset_index(drop=True)\n    }\n\n#LABEL ALLOCATION IN CLIENT SPLIT\n\n\ndef allocate_client_labeled_data_non_iid(balanced_df, source_allocation_matrix, source_map, clients, target_per_client=3000):\n    \n    pneu_labeled_df = balanced_df[balanced_df['label_id'] == 1].copy().reset_index(drop=True)\n    normal_labeled_df = balanced_df[balanced_df['label_id'] == 0].copy().reset_index(drop=True)\n    \n    print(f\"Total Pneumonia samples: {len(pneu_labeled_df)}\")\n    print(f\"Total Normal samples: {len(normal_labeled_df)}\")\n    print(f\"\\nTarget samples per client: ~{target_per_client}\")\n    \n    final_client_datasets = {}\n    \n    for cid in range(clients):\n        client_samples = []\n        \n        #For each source, allocate according to matrix\n        for i, source in enumerate(source_map):\n            source_pneu = pneu_labeled_df[pneu_labeled_df['source'] == source].copy()\n            source_normal = normal_labeled_df[normal_labeled_df['source'] == source].copy()\n            \n            #Get percentage for this client-source combo\n            pct = source_allocation_matrix[cid, i]\n            \n            #Calculate target samples from this source\n            n_from_source = int(target_per_client * pct)\n            n_pneu_target = n_from_source // 2  # Half pneumonia\n            n_normal_target = n_from_source // 2  # Half normal\n            \n            #Sample pneumonia\n            if n_pneu_target > 0 and len(source_pneu) > 0:\n                replace_pneu = n_pneu_target > len(source_pneu)\n                n_pneu_actual = min(n_pneu_target, len(source_pneu) * 3) if replace_pneu else n_pneu_target\n                sampled_pneu = source_pneu.sample(n=n_pneu_actual, replace=replace_pneu, random_state=42+cid)\n                client_samples.append(sampled_pneu)\n            \n            #Sample normal\n            if n_normal_target > 0 and len(source_normal) > 0:\n                replace_normal = n_normal_target > len(source_normal)\n                n_normal_actual = min(n_normal_target, len(source_normal) * 3) if replace_normal else n_normal_target\n                sampled_normal = source_normal.sample(n=n_normal_actual, replace=replace_normal, random_state=42+cid)\n                client_samples.append(sampled_normal)\n        \n        #Combine all samples for this client\n        if not client_samples:\n            print(f\"WARNING: Client {cid} has no samples!\")\n            continue\n            \n        client_df = pd.concat(client_samples, ignore_index=True).sample(frac=1, random_state=42+cid).reset_index(drop=True)\n        \n        #Remove any duplicate indices\n        client_df = client_df.drop_duplicates(subset=['path']).reset_index(drop=True)\n        \n        #Split into SSL, FL_train, Val\n        stratify = client_df['label_id'] if len(client_df['label_id'].unique()) > 1 else None\n        \n        train_ssl, val_df = train_test_split(\n            client_df, \n            test_size=VAL_FRACTION, \n            stratify=stratify, \n            random_state=42\n        )\n        \n        fl_train_relative_size = FL_TRAIN_FRACTION / (1 - VAL_FRACTION)\n        stratify_train = train_ssl['label_id'] if len(train_ssl['label_id'].unique()) > 1 else None\n        \n        ssl_df, fl_train_df = train_test_split(\n            train_ssl, \n            test_size=fl_train_relative_size, \n            stratify=stratify_train, \n            random_state=42\n        )\n        \n        # Calculate metrics\n        pneu_ratio = fl_train_df['label_id'].mean() * 100 if len(fl_train_df) > 0 else 0\n        source_dist = fl_train_df['source'].value_counts()\n        source_pct = (source_dist / len(fl_train_df) * 100).round(1) if len(fl_train_df) > 0 else {}\n        \n        final_client_datasets[cid] = {\n            'ssl': ssl_df.reset_index(drop=True),\n            'fl_train': fl_train_df.reset_index(drop=True),\n            'val': val_df.reset_index(drop=True),\n            'pneu_ratio': pneu_ratio\n        }\n        \n    # Final Summary\n    print(\"\\n\" + \"=\"*60)\n    print(\"CLIENT DATA SPLIT SUMMARY BEFORE SSL\")\n    print(\"=\"*60)\n    for cid in range(clients):\n        ssl_size = len(final_client_datasets[cid]['ssl'])\n        fl_train_size = len(final_client_datasets[cid]['fl_train'])\n        val_size = len(final_client_datasets[cid]['val'])\n        pneu_ratio = final_client_datasets[cid]['pneu_ratio']\n        \n        print(f\"Client {cid}: Total={ssl_size + fl_train_size + val_size:>5} | \"\n              f\"SSL={ssl_size:>4} | FL_train={fl_train_size:>4} | Val={val_size:>4} | \"\n              f\"Pneu={pneu_ratio:>5.1f}%\")\n    \n    return final_client_datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T17:46:01.403440Z","iopub.execute_input":"2025-12-03T17:46:01.403748Z","iopub.status.idle":"2025-12-03T17:46:01.418941Z","shell.execute_reply.started":"2025-12-03T17:46:01.403727Z","shell.execute_reply":"2025-12-03T17:46:01.418313Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"final_client_datasets = allocate_client_labeled_data_non_iid(\n    balanced_df=balanced_df, \n    source_allocation_matrix=source_allocation_matrix, \n    source_map=source_map, \n    clients=clients,\n    target_per_client=3000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T17:46:04.045252Z","iopub.execute_input":"2025-12-03T17:46:04.045602Z","iopub.status.idle":"2025-12-03T17:46:04.192032Z","shell.execute_reply.started":"2025-12-03T17:46:04.045580Z","shell.execute_reply":"2025-12-03T17:46:04.191402Z"}},"outputs":[{"name":"stdout","text":"Total Pneumonia samples: 15343\nTotal Normal samples: 26850\n\nTarget samples per client: ~3000\n\n============================================================\nCLIENT DATA SPLIT SUMMARY BEFORE SSL\n============================================================\nClient 0: Total= 1746 | SSL=  87 | FL_train=1135 | Val= 524 | Pneu= 50.6%\nClient 1: Total= 2169 | SSL= 108 | FL_train=1410 | Val= 651 | Pneu= 54.5%\nClient 2: Total= 2550 | SSL= 127 | FL_train=1658 | Val= 765 | Pneu= 52.4%\nClient 3: Total= 2245 | SSL= 112 | FL_train=1459 | Val= 674 | Pneu= 59.4%\nClient 4: Total= 2389 | SSL= 119 | FL_train=1553 | Val= 717 | Pneu= 49.6%\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# --- Transforms ---\nMEAN = [0.485, 0.456, 0.406]\nSTD = [0.229, 0.224, 0.225]\nnormalize = transforms.Normalize(mean=MEAN, std=STD)\n\ntrain_transforms = transforms.Compose([\n    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ToTensor(),\n    normalize\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize(IMG_SIZE),\n    transforms.CenterCrop(IMG_SIZE),\n    transforms.ToTensor(),\n    normalize\n])\n\n# --- Dataset Class ---\nclass XRayDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = row['path']\n        try:\n            img = Image.open(img_path).convert('RGB')\n        except Exception as e:\n            img = Image.new('RGB', (IMG_SIZE, IMG_SIZE), color='black')\n        \n        if self.transform:\n            img = self.transform(img)\n        label = torch.tensor(row['label_id'], dtype=torch.float32)\n        return img, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T17:46:16.028532Z","iopub.execute_input":"2025-12-03T17:46:16.029169Z","iopub.status.idle":"2025-12-03T17:46:16.036109Z","shell.execute_reply.started":"2025-12-03T17:46:16.029143Z","shell.execute_reply":"2025-12-03T17:46:16.035340Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Add import at the top if not already imported\nfrom torch.utils.data import WeightedRandomSampler\n\n# Define constants if not already defined\nFL_BATCH_SIZE = 32\nVAL_BATCH_SIZE = 32\nNUM_WORKERS = 4\n\n# --- FL training transforms ---\ndef get_fl_train_transforms(client_id):\n    \"\"\"Client-specific transforms that ALWAYS output 224x224\"\"\"\n    \n    # All clients start with same base\n    all_transforms = [\n        transforms.Resize((IMG_SIZE, IMG_SIZE)),  # Force exact size first\n    ]\n    \n    # Client-specific augmentation after sizing\n    if client_id == 0:\n        all_transforms.extend([\n            transforms.ColorJitter(brightness=0.3, contrast=0.3),\n        ])\n    elif client_id == 1:\n        all_transforms.extend([\n            transforms.RandomRotation(10),\n        ])\n    elif client_id == 2:\n        all_transforms.extend([\n            transforms.ColorJitter(saturation=0.3, hue=0.1),\n        ])\n    elif client_id == 3:\n        all_transforms.extend([\n            transforms.RandomAffine(degrees=5, translate=(0.05, 0.05)),\n        ])\n    else:\n        all_transforms.extend([\n            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n        ])\n    \n    all_transforms.extend([\n        transforms.RandomHorizontalFlip(p=0.5),\n        transforms.ToTensor(),\n        normalize\n    ])\n    \n    return transforms.Compose(all_transforms)\n\n# Validation transforms\nval_transforms = transforms.Compose([\n    transforms.Resize(IMG_SIZE),\n    transforms.CenterCrop(IMG_SIZE),\n    transforms.ToTensor(),\n    normalize\n])\n\nprint(\"Transforms defined\")\n\n# --- Create DataLoaders ---\ndef create_client_dataloaders(client_datasets):\n    \"\"\"Creates all dataloaders for all clients\"\"\"\n    \n    client_loaders = {}\n    \n    for client_id in range(len(client_datasets)):\n        client_data = client_datasets[client_id]\n        \n        # 1. FL Train DataLoader\n        fl_train_dataset = XRayDataset(\n            df=client_data['fl_train'],\n            transform=get_fl_train_transforms(client_id))\n        \n        # Create weighted sampler for class balance\n        labels = client_data['fl_train']['label_id'].values\n        class_counts = np.bincount(labels.astype(int))\n        class_weights = 1.0 / class_counts\n        sample_weights = class_weights[labels.astype(int)]\n        \n        sampler = WeightedRandomSampler(\n            weights=torch.tensor(sample_weights, dtype=torch.float32),\n            num_samples=len(sample_weights),\n            replacement=True\n        )\n        \n        fl_train_loader = DataLoader(\n            fl_train_dataset,\n            batch_size=FL_BATCH_SIZE,\n            sampler=sampler,  \n            num_workers=NUM_WORKERS,\n            pin_memory=True,\n            drop_last=True\n        )\n        \n        # 2. Validation DataLoader\n        val_dataset = XRayDataset(\n            df=client_data['val'],\n            transform=val_transforms)\n        val_loader = DataLoader(\n            val_dataset,\n            batch_size=VAL_BATCH_SIZE,\n            shuffle=False,\n            num_workers=NUM_WORKERS,\n            pin_memory=True\n        )\n        \n        # 3. SSL DataLoader (if SSL data exists in client_data)\n        ssl_loader = None\n        if 'ssl' in client_data and len(client_data['ssl']) > 0:\n            ssl_dataset = XRayDataset(\n                df=client_data['ssl'],\n                transform=get_fl_train_transforms(client_id))  # Use same transforms as FL train\n            ssl_loader = DataLoader(\n                ssl_dataset,\n                batch_size=FL_BATCH_SIZE,\n                shuffle=True,\n                num_workers=NUM_WORKERS,\n                pin_memory=True\n            )\n        \n        client_loaders[client_id] = {\n            'ssl': ssl_loader,\n            'fl_train': fl_train_loader,\n            'val': val_loader\n        }\n        \n        print(f\"Client {client_id}: SSL={len(client_data['ssl']) if 'ssl' in client_data else 0} | \"\n              f\"FL_train={len(fl_train_dataset)} | Val={len(val_dataset)}\")\n    \n    return client_loaders\n\nclient_dataloaders = create_client_dataloaders(final_client_datasets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:12:09.192902Z","iopub.execute_input":"2025-12-03T18:12:09.193180Z","iopub.status.idle":"2025-12-03T18:12:09.215263Z","shell.execute_reply.started":"2025-12-03T18:12:09.193158Z","shell.execute_reply":"2025-12-03T18:12:09.214481Z"}},"outputs":[{"name":"stdout","text":"Transforms defined\nClient 0: SSL=87 | FL_train=1135 | Val=524\nClient 1: SSL=108 | FL_train=1410 | Val=651\nClient 2: SSL=127 | FL_train=1658 | Val=765\nClient 3: SSL=112 | FL_train=1459 | Val=674\nClient 4: SSL=119 | FL_train=1553 | Val=717\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"test_dataset = XRayDataset(global_test_df, transform=val_transforms)\nglobal_test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\nprint(f\"Global test loader: {len(test_dataset)} samples\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:12:16.118708Z","iopub.execute_input":"2025-12-03T18:12:16.119401Z","iopub.status.idle":"2025-12-03T18:12:16.129631Z","shell.execute_reply.started":"2025-12-03T18:12:16.119375Z","shell.execute_reply":"2025-12-03T18:12:16.128986Z"}},"outputs":[{"name":"stdout","text":"Global test loader: 6329 samples\n","output_type":"stream"}],"execution_count":36},{"cell_type":"markdown","source":"# CNN Setup","metadata":{}},{"cell_type":"code","source":"# --- Simple CNN Model Definition (BASELINE) ---\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        # Convolutional layers\n        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n        \n        # Pooling layer\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        # Dropout\n        self.dropout = nn.Dropout(0.3)\n        \n        # Calculate the size after convolutions and pooling\n        # Input: 224x224\n        # After conv1+pool: 112x112\n        # After conv2+pool: 56x56\n        # After conv3+pool: 28x28\n        # After conv4+pool: 14x14\n        # Flatten: 256 * 14 * 14 = 50176\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(256 * 14 * 14, 512)\n        self.fc2 = nn.Linear(512, 128)\n        self.fc3 = nn.Linear(128, 1)\n        \n        # Batch normalization\n        self.bn1 = nn.BatchNorm2d(32)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.bn3 = nn.BatchNorm2d(128)\n        self.bn4 = nn.BatchNorm2d(256)\n        \n    def forward(self, x):\n        # Convolutional layers with ReLU and pooling\n        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n        \n        # Flatten\n        x = x.view(x.size(0), -1)\n        \n        # Fully connected layers\n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.dropout(F.relu(self.fc2(x)))\n        x = self.fc3(x)\n        \n        return x.squeeze(-1)\n\n# --- Federated Learning Model (BASELINE) ---\nclass FedCNNModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        # Use the simple CNN as backbone\n        self.backbone = SimpleCNN()\n        \n    def forward(self, x):\n        return self.backbone(x)\n\n# Initialize model\nglobal_model = FedCNNModel().to(DEVICE)\nprint(f\"Simple CNN model initialized\")\nprint(f\"Total parameters: {sum(p.numel() for p in global_model.parameters()):,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:12:23.329216Z","iopub.execute_input":"2025-12-03T18:12:23.329518Z","iopub.status.idle":"2025-12-03T18:12:23.574553Z","shell.execute_reply.started":"2025-12-03T18:12:23.329487Z","shell.execute_reply":"2025-12-03T18:12:23.573884Z"}},"outputs":[{"name":"stdout","text":"Simple CNN model initialized\nTotal parameters: 26,145,793\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"# --- Simple CNN Model Definition ---\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)   \n        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1) \n        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)     \n        \n        # Pooling layer\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        # Batch normalization\n        self.bn1 = nn.BatchNorm2d(16)\n        self.bn2 = nn.BatchNorm2d(32)\n        self.bn3 = nn.BatchNorm2d(64)\n\n        self.classification_head = nn.Sequential(\n            nn.LayerNorm(64 * 28 * 28),            # Like your ViT's LayerNorm\n            nn.Linear(64 * 28 * 28, 192),          # 384→192 in ViT, here 50176→192\n            nn.GELU(),                             # Same activation\n            nn.Dropout(0.3),                       # Same dropout\n            nn.Linear(192, 1)                      # Same output dimension\n        )\n        \n        self._initialize_weights()\n        \n    def _initialize_weights(self):\n        \"\"\"Initialize like ViT: Xavier uniform, zero bias\"\"\"\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.xavier_uniform_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Conv2d):\n                nn.init.xavier_uniform_(m.weight)\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n    \n    def forward(self, x):\n        # Feature extraction (3 conv layers, comparable to ViT encoder)\n        x = self.pool(F.relu(self.bn1(self.conv1(x))))    # 224→112\n        x = self.pool(F.relu(self.bn2(self.conv2(x))))    # 112→56\n        x = self.pool(F.relu(self.bn3(self.conv3(x))))    # 56→28\n        \n        # Flatten\n        x = x.view(x.size(0), -1)  # [batch, 64*28*28]\n        \n        x = self.classification_head(x)\n        \n        return x.squeeze(-1)\n\n# --- Federated Learning Model (BASELINE) ---\nclass FedCNNModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        #Use the CNN as backbone\n        self.backbone = SimpleCNN()\n        \n    def forward(self, x):\n        return self.backbone(x)\n\n# Initialize model\nglobal_model = FedCNNModel().to(DEVICE)\nprint(f\"Lightweight CNN with ViT-style head initialized\")\nprint(f\"Total parameters: {sum(p.numel() for p in global_model.parameters()):,}\")\n\n#Breakdown of parameters\nprint(\"\\nParameter breakdown:\")\nfor name, param in global_model.named_parameters():\n    if param.requires_grad:\n        print(f\"  {name}: {param.numel():,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:24:58.984212Z","iopub.execute_input":"2025-12-03T18:24:58.984809Z","iopub.status.idle":"2025-12-03T18:24:59.142335Z","shell.execute_reply.started":"2025-12-03T18:24:58.984780Z","shell.execute_reply":"2025-12-03T18:24:59.141683Z"}},"outputs":[{"name":"stdout","text":"Lightweight CNN with ViT-style head initialized\nTotal parameters: 9,758,337\n\nParameter breakdown:\n  backbone.conv1.weight: 432\n  backbone.conv1.bias: 16\n  backbone.conv2.weight: 4,608\n  backbone.conv2.bias: 32\n  backbone.conv3.weight: 18,432\n  backbone.conv3.bias: 64\n  backbone.bn1.weight: 16\n  backbone.bn1.bias: 16\n  backbone.bn2.weight: 32\n  backbone.bn2.bias: 32\n  backbone.bn3.weight: 64\n  backbone.bn3.bias: 64\n  backbone.classification_head.0.weight: 50,176\n  backbone.classification_head.0.bias: 50,176\n  backbone.classification_head.1.weight: 9,633,792\n  backbone.classification_head.1.bias: 192\n  backbone.classification_head.4.weight: 192\n  backbone.classification_head.4.bias: 1\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"###2\n# --- Strong CNN ---\n\nclass RealisticCNN(nn.Module):\n    def __init__(self, dropout_rate=0.5):\n        super().__init__()\n        \n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        \n        # 4 blocks with 2 layers each (ResNet-18 depth)\n        self.layer1 = self._make_layer(64, 64, 2, stride=1, dropout=dropout_rate*0.5)\n        self.layer2 = self._make_layer(64, 128, 2, stride=2, dropout=dropout_rate)\n        self.layer3 = self._make_layer(128, 256, 2, stride=2, dropout=dropout_rate)\n        self.layer4 = self._make_layer(256, 512, 2, stride=2, dropout=dropout_rate)\n        \n        # Global pooling\n        self.avgpool = nn.AdaptiveAvgPool2d(1)\n        \n        # Moderate classifier\n        self.fc = nn.Sequential(\n            nn.Dropout(dropout_rate),\n            nn.Linear(512, 256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(dropout_rate*0.5),\n            nn.Linear(256, 1)\n        )\n        \n        # Proper initialization\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.ones_(m.weight)\n                nn.init.zeros_(m.bias)\n    \n    def _make_layer(self, in_channels, out_channels, blocks, stride, dropout):\n        downsample = None\n        if stride != 1 or in_channels != out_channels:\n            downsample = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels),\n            )\n        \n        layers = []\n        layers.append(ResidualBlock(in_channels, out_channels, stride, downsample, dropout))\n        \n        for _ in range(1, blocks):\n            layers.append(ResidualBlock(out_channels, out_channels, 1, None, dropout))\n            \n        return nn.Sequential(*layers)\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        \n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        \n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        \n        return x.squeeze(-1)\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1, downsample=None, dropout=0.3):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n        self.dropout = nn.Dropout2d(dropout)  # Spatial dropout\n        self.downsample = downsample\n    \n    def forward(self, x):\n        identity = x\n        \n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.dropout(out)\n        \n        out = self.conv2(out)\n        out = self.bn2(out)\n        \n        if self.downsample is not None:\n            identity = self.downsample(x)\n        \n        out += identity\n        out = self.relu(out)\n        \n        return out\n\n#wrapper\nclass FedCNNModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = RealisticCNN(dropout_rate=0.5)  # HIGH dropout for FL\n    \n    def forward(self, x):\n        return self.backbone(x)\n\nglobal_model = FedCNNModel().to(DEVICE)\nprint(f\"Realistic CNN (ResNet-18 level) initialized\")\nprint(f\"Total parameters: {sum(p.numel() for p in global_model.parameters()):,}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **TRAINING**","metadata":{}},{"cell_type":"code","source":"# --- Training Functions ---\nLOCAL_EPOCHS = 15\nFL_LR = 1e-5\nGLOBAL_ROUNDS = 15\nMU = 0.5  # FedProx proximal term coefficient\ncriterion = nn.BCEWithLogitsLoss()\n\ndef train_local_fedprox(client_id, train_loader, global_model, mu=MU, device=DEVICE):\n    \"\"\"Vanilla FedProx local training with proximal term\"\"\"\n    local_model = copy.deepcopy(global_model)\n    local_model.to(device)\n    local_model.train()\n    \n    # Single optimizer for all parameters (simpler than ViT)\n    optimizer = optim.AdamW(local_model.parameters(), lr=FL_LR, weight_decay=0.01)\n    \n    # Save global parameters for proximal term\n    global_params = {name: param.clone().detach() for name, param in global_model.named_parameters()}\n    \n    for epoch in range(LOCAL_EPOCHS):\n        total_loss = 0.0\n        correct = 0\n        total = 0\n        \n        for images, labels in train_loader:\n            images = images.to(device)\n            labels = labels.to(device).float()\n            \n            optimizer.zero_grad()\n            logits = local_model(images)\n            ce_loss = criterion(logits, labels)\n            \n            # FedProx proximal term: (mu/2) * ||w - w_global||^2\n            prox_term = 0.0\n            for name, param in local_model.named_parameters():\n                prox_term += ((param - global_params[name]) ** 2).sum()\n            prox_term = (mu / 2.0) * prox_term\n            \n            # Total loss = CE loss + proximal term\n            loss = ce_loss + prox_term\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(local_model.parameters(), 1.0)\n            optimizer.step()\n            \n            total_loss += loss.item() * images.size(0)\n            preds = (torch.sigmoid(logits) > 0.5).long()\n            correct += (preds == labels.long()).sum().item()\n            total += labels.size(0)\n        \n        if epoch == LOCAL_EPOCHS - 1:\n            avg_loss = total_loss / total\n            accuracy = correct / total\n            print(f\"  Client {client_id} Epoch {epoch+1}: Loss={avg_loss:.4f}, Acc={accuracy:.2%}\")\n    \n    return local_model.state_dict()\n\ndef evaluate_model(model, val_loader, device=DEVICE):\n    model.eval()\n    model.to(device)\n    total_loss = 0.0\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device).float()\n            logits = model(images)\n            loss = criterion(logits, labels)\n            total_loss += loss.item() * images.size(0)\n            preds = (torch.sigmoid(logits) > 0.4).long()\n            all_preds.extend(preds.cpu().tolist())\n            all_labels.extend(labels.long().cpu().tolist())\n    \n    avg_loss = total_loss / len(val_loader.dataset)\n    accuracy = sum([p == l for p, l in zip(all_preds, all_labels)]) / len(all_labels)\n    \n    # Calculate F1 score\n    TP = sum([(p==1 and l==1) for p,l in zip(all_preds, all_labels)])\n    FP = sum([(p==1 and l==0) for p,l in zip(all_preds, all_labels)])\n    FN = sum([(p==0 and l==1) for p,l in zip(all_preds, all_labels)])\n    \n    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n    \n    return avg_loss, accuracy, f1\n\ndef vanilla_fedavg(client_updates):\n    \"\"\"Simple averaging of client models with dtype handling\"\"\"\n    global_state = copy.deepcopy(client_updates[0])\n    \n    for key in global_state.keys():\n        # Initialize sum with proper dtype\n        if global_state[key].dtype in [torch.int64, torch.int32, torch.int16, torch.int8, torch.uint8]:\n            # For integer parameters, keep as float for averaging, then convert back\n            temp_sum = torch.zeros_like(global_state[key], dtype=torch.float32)\n            \n            for client_state in client_updates:\n                temp_sum += client_state[key].float()\n            \n            # Average and convert back to original dtype\n            global_state[key] = (temp_sum / len(client_updates)).to(global_state[key].dtype)\n        else:\n            # For float parameters, proceed normally\n            global_state[key] = torch.zeros_like(global_state[key])\n            for client_state in client_updates:\n                global_state[key] += client_state[key]\n            global_state[key] /= len(client_updates)\n    \n    return global_state","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:25:12.908600Z","iopub.execute_input":"2025-12-03T18:25:12.909561Z","iopub.status.idle":"2025-12-03T18:25:12.923146Z","shell.execute_reply.started":"2025-12-03T18:25:12.909530Z","shell.execute_reply":"2025-12-03T18:25:12.922522Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"# --- Main FedProx Training Loop with ONLY Local Validation ---\nprint(\"\\n\" + \"=\"*80)\nprint(f\"SIMPLE CNN BASELINE - FEDPROX TRAINING (mu={MU})\")\nprint(\"=\"*80)\n\n# Track LOCAL validation metrics only during FL\nlocal_val_losses = {client_id: [] for client_id in range(clients)}\nlocal_val_accs = {client_id: [] for client_id in range(clients)}\nlocal_val_f1s = {client_id: [] for client_id in range(clients)}\n\n#AVERAGE local validation across clients per round\navg_local_val_losses = []\navg_local_val_accs = []\navg_local_val_f1s = []\n\nfor round_num in range(1, GLOBAL_ROUNDS + 1):\n    print(f\"\\n{'='*60}\")\n    print(f\"ROUND {round_num}/{GLOBAL_ROUNDS}\")\n    print(f\"{'='*60}\")\n    \n    client_updates = []\n    \n    # Train all clients\n    for client_id in range(clients):\n        print(f\"Training Client {client_id}...\")\n        \n        # Train local model\n        local_state = train_local_fedprox(\n            client_id, \n            client_dataloaders[client_id]['fl_train'], \n            global_model, \n            mu=MU, \n            device=DEVICE\n        )\n        client_updates.append(local_state)\n        \n        # Local Validation after training\n        print(f\"Validating Client {client_id} locally...\")\n        \n        # Create temporary model with local updates for validation\n        local_model_temp = copy.deepcopy(global_model)\n        local_model_temp.load_state_dict(local_state)\n        local_model_temp.to(DEVICE)\n        \n        # Evaluate on client's validation set\n        val_loss, val_acc, val_f1 = evaluate_model(\n            local_model_temp, \n            client_dataloaders[client_id]['val'], \n            DEVICE\n        )\n        \n        # Store local validation metrics\n        local_val_losses[client_id].append(val_loss)\n        local_val_accs[client_id].append(val_acc)\n        local_val_f1s[client_id].append(val_f1)\n        \n        print(f\"  Client {client_id} Local Val: Loss={val_loss:.4f}, Acc={val_acc:.2%}, F1={val_f1:.4f}\")\n    \n    # Simple averaging (no weighted aggregation for baseline)\n    print(\"\\nAggregating client updates (simple averaging)...\")\n    global_state = vanilla_fedavg(client_updates)\n    global_model.load_state_dict(global_state)\n    \n    # Calculate AVERAGE local validation metrics for this round\n    round_avg_loss = np.mean([local_val_losses[cid][-1] for cid in range(clients)])\n    round_avg_acc = np.mean([local_val_accs[cid][-1] for cid in range(clients)])\n    round_avg_f1 = np.mean([local_val_f1s[cid][-1] for cid in range(clients)])\n    \n    avg_local_val_losses.append(round_avg_loss)\n    avg_local_val_accs.append(round_avg_acc)\n    avg_local_val_f1s.append(round_avg_f1)\n    \n    print(f\"\\nRound {round_num} Summary:\")\n    print(f\"  Avg Local Val Loss: {round_avg_loss:.4f}\")\n    print(f\"  Avg Local Val Acc:  {round_avg_acc:.2%}\")\n    print(f\"  Avg Local Val F1:   {round_avg_f1:.4f}\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"FEDERATED LEARNING TRAINING COMPLETE\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T18:25:17.068839Z","iopub.execute_input":"2025-12-03T18:25:17.069139Z","iopub.status.idle":"2025-12-03T20:39:21.185120Z","shell.execute_reply.started":"2025-12-03T18:25:17.069116Z","shell.execute_reply":"2025-12-03T20:39:21.184379Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nSIMPLE CNN BASELINE - FEDPROX TRAINING (mu=0.5)\n================================================================================\n\n============================================================\nROUND 1/15\n============================================================\nTraining Client 0...\n  Client 0 Epoch 15: Loss=0.3119, Acc=90.80%\nValidating Client 0 locally...\n  Client 0 Local Val: Loss=0.6553, Acc=71.56%, F1=0.6915\nTraining Client 1...\n  Client 1 Epoch 15: Loss=0.5427, Acc=76.92%\nValidating Client 1 locally...\n  Client 1 Local Val: Loss=0.6446, Acc=65.90%, F1=0.6829\nTraining Client 2...\n  Client 2 Epoch 15: Loss=0.2614, Acc=94.67%\nValidating Client 2 locally...\n  Client 2 Local Val: Loss=0.4328, Acc=78.69%, F1=0.8005\nTraining Client 3...\n  Client 3 Epoch 15: Loss=0.4930, Acc=79.31%\nValidating Client 3 locally...\n  Client 3 Local Val: Loss=0.4654, Acc=78.49%, F1=0.8129\nTraining Client 4...\n  Client 4 Epoch 15: Loss=0.3605, Acc=89.65%\nValidating Client 4 locally...\n  Client 4 Local Val: Loss=0.5622, Acc=70.85%, F1=0.7331\n\nAggregating client updates (simple averaging)...\n\nRound 1 Summary:\n  Avg Local Val Loss: 0.5521\n  Avg Local Val Acc:  73.10%\n  Avg Local Val F1:   0.7442\n\n============================================================\nROUND 2/15\n============================================================\nTraining Client 0...\n  Client 0 Epoch 15: Loss=0.2221, Acc=94.20%\nValidating Client 0 locally...\n  Client 0 Local Val: Loss=0.5953, Acc=72.52%, F1=0.7037\nTraining Client 1...\n  Client 1 Epoch 15: Loss=0.4929, Acc=77.63%\nValidating Client 1 locally...\n  Client 1 Local Val: Loss=0.5942, Acc=67.90%, F1=0.7202\nTraining Client 2...\n  Client 2 Epoch 15: Loss=0.1992, Acc=96.45%\nValidating Client 2 locally...\n  Client 2 Local Val: Loss=0.4056, Acc=81.18%, F1=0.8252\nTraining Client 3...\n  Client 3 Epoch 15: Loss=0.4595, Acc=81.11%\nValidating Client 3 locally...\n  Client 3 Local Val: Loss=0.4331, Acc=77.45%, F1=0.8237\nTraining Client 4...\n  Client 4 Epoch 15: Loss=0.2721, Acc=93.88%\nValidating Client 4 locally...\n  Client 4 Local Val: Loss=0.5545, Acc=71.27%, F1=0.7406\n\nAggregating client updates (simple averaging)...\n\nRound 2 Summary:\n  Avg Local Val Loss: 0.5165\n  Avg Local Val Acc:  74.06%\n  Avg Local Val F1:   0.7627\n\n============================================================\nROUND 3/15\n============================================================\nTraining Client 0...\n  Client 0 Epoch 15: Loss=0.1838, Acc=96.79%\nValidating Client 0 locally...\n  Client 0 Local Val: Loss=0.5234, Acc=78.82%, F1=0.7819\nTraining Client 1...\n  Client 1 Epoch 15: Loss=0.4517, Acc=80.97%\nValidating Client 1 locally...\n  Client 1 Local Val: Loss=0.5905, Acc=68.97%, F1=0.7314\nTraining Client 2...\n  Client 2 Epoch 15: Loss=0.1627, Acc=96.63%\nValidating Client 2 locally...\n  Client 2 Local Val: Loss=0.3887, Acc=80.78%, F1=0.8264\nTraining Client 3...\n  Client 3 Epoch 15: Loss=0.4256, Acc=81.67%\nValidating Client 3 locally...\n  Client 3 Local Val: Loss=0.3970, Acc=80.27%, F1=0.8392\nTraining Client 4...\n  Client 4 Epoch 15: Loss=0.2322, Acc=94.60%\nValidating Client 4 locally...\n  Client 4 Local Val: Loss=0.5117, Acc=74.90%, F1=0.7756\n\nAggregating client updates (simple averaging)...\n\nRound 3 Summary:\n  Avg Local Val Loss: 0.4823\n  Avg Local Val Acc:  76.75%\n  Avg Local Val F1:   0.7909\n\n============================================================\nROUND 4/15\n============================================================\nTraining Client 0...\n  Client 0 Epoch 15: Loss=0.1506, Acc=97.05%\nValidating Client 0 locally...\n  Client 0 Local Val: Loss=0.4612, Acc=76.72%, F1=0.7837\nTraining Client 1...\n  Client 1 Epoch 15: Loss=0.4367, Acc=81.18%\nValidating Client 1 locally...\n  Client 1 Local Val: Loss=0.5763, Acc=70.81%, F1=0.7390\nTraining Client 2...\n  Client 2 Epoch 15: Loss=0.1385, Acc=97.79%\nValidating Client 2 locally...\n  Client 2 Local Val: Loss=0.3817, Acc=82.48%, F1=0.8405\nTraining Client 3...\n  Client 3 Epoch 15: Loss=0.4079, Acc=83.89%\nValidating Client 3 locally...\n  Client 3 Local Val: Loss=0.4079, Acc=78.19%, F1=0.8264\nTraining Client 4...\n  Client 4 Epoch 15: Loss=0.1966, Acc=95.83%\nValidating Client 4 locally...\n  Client 4 Local Val: Loss=0.4964, Acc=76.71%, F1=0.7811\n\nAggregating client updates (simple averaging)...\n\nRound 4 Summary:\n  Avg Local Val Loss: 0.4647\n  Avg Local Val Acc:  76.98%\n  Avg Local Val F1:   0.7941\n\n============================================================\nROUND 5/15\n============================================================\nTraining Client 0...\n  Client 0 Epoch 15: Loss=0.1337, Acc=97.77%\nValidating Client 0 locally...\n  Client 0 Local Val: Loss=0.4675, Acc=79.58%, F1=0.8022\nTraining Client 1...\n  Client 1 Epoch 15: Loss=0.4150, Acc=83.45%\nValidating Client 1 locally...\n  Client 1 Local Val: Loss=0.5883, Acc=72.81%, F1=0.7559\nTraining Client 2...\n  Client 2 Epoch 15: Loss=0.1090, Acc=98.53%\nValidating Client 2 locally...\n  Client 2 Local Val: Loss=0.3692, Acc=83.92%, F1=0.8585\nTraining Client 3...\n  Client 3 Epoch 15: Loss=0.3796, Acc=84.58%\nValidating Client 3 locally...\n  Client 3 Local Val: Loss=0.4047, Acc=79.97%, F1=0.8387\nTraining Client 4...\n  Client 4 Epoch 15: Loss=0.1644, Acc=97.46%\nValidating Client 4 locally...\n  Client 4 Local Val: Loss=0.5107, Acc=75.45%, F1=0.7634\n\nAggregating client updates (simple averaging)...\n\nRound 5 Summary:\n  Avg Local Val Loss: 0.4681\n  Avg Local Val Acc:  78.35%\n  Avg Local Val F1:   0.8037\n\n============================================================\nROUND 6/15\n============================================================\nTraining Client 0...\n  Client 0 Epoch 15: Loss=0.1286, Acc=97.32%\nValidating Client 0 locally...\n  Client 0 Local Val: Loss=0.4768, Acc=78.24%, F1=0.7865\nTraining Client 1...\n  Client 1 Epoch 15: Loss=0.3924, Acc=85.23%\nValidating Client 1 locally...\n  Client 1 Local Val: Loss=0.5785, Acc=71.58%, F1=0.7427\nTraining Client 2...\n  Client 2 Epoch 15: Loss=0.0954, Acc=99.02%\nValidating Client 2 locally...\n  Client 2 Local Val: Loss=0.3780, Acc=83.53%, F1=0.8482\nTraining Client 3...\n  Client 3 Epoch 15: Loss=0.4287, Acc=83.19%\nValidating Client 3 locally...\n  Client 3 Local Val: Loss=0.3958, Acc=80.27%, F1=0.8426\nTraining Client 4...\n  Client 4 Epoch 15: Loss=0.1489, Acc=97.79%\nValidating Client 4 locally...\n  Client 4 Local Val: Loss=0.5014, Acc=76.15%, F1=0.7776\n\nAggregating client updates (simple averaging)...\n\nRound 6 Summary:\n  Avg Local Val Loss: 0.4661\n  Avg Local Val Acc:  77.95%\n  Avg Local Val F1:   0.7995\n\n============================================================\nROUND 7/15\n============================================================\nTraining Client 0...\n  Client 0 Epoch 15: Loss=0.1213, Acc=97.86%\nValidating Client 0 locally...\n  Client 0 Local Val: Loss=0.4415, Acc=78.82%, F1=0.8070\nTraining Client 1...\n  Client 1 Epoch 15: Loss=0.3685, Acc=86.08%\nValidating Client 1 locally...\n  Client 1 Local Val: Loss=0.5871, Acc=71.27%, F1=0.7568\nTraining Client 2...\n  Client 2 Epoch 15: Loss=0.0868, Acc=99.20%\nValidating Client 2 locally...\n  Client 2 Local Val: Loss=0.3662, Acc=83.66%, F1=0.8538\nTraining Client 3...\n  Client 3 Epoch 15: Loss=0.3790, Acc=84.44%\nValidating Client 3 locally...\n  Client 3 Local Val: Loss=0.3688, Acc=81.75%, F1=0.8502\nTraining Client 4...\n  Client 4 Epoch 15: Loss=0.1408, Acc=97.33%\nValidating Client 4 locally...\n  Client 4 Local Val: Loss=0.4806, Acc=77.68%, F1=0.7889\n\nAggregating client updates (simple averaging)...\n\nRound 7 Summary:\n  Avg Local Val Loss: 0.4488\n  Avg Local Val Acc:  78.64%\n  Avg Local Val F1:   0.8113\n\n============================================================\nROUND 8/15\n============================================================\nTraining Client 0...\n  Client 0 Epoch 15: Loss=0.0998, Acc=98.48%\nValidating Client 0 locally...\n  Client 0 Local Val: Loss=0.4434, Acc=79.58%, F1=0.8037\nTraining Client 1...\n  Client 1 Epoch 15: Loss=0.3818, Acc=84.80%\nValidating Client 1 locally...\n  Client 1 Local Val: Loss=0.5777, Acc=71.27%, F1=0.7562\nTraining Client 2...\n  Client 2 Epoch 15: Loss=0.0814, Acc=98.90%\nValidating Client 2 locally...\n  Client 2 Local Val: Loss=0.3122, Acc=86.54%, F1=0.8784\nTraining Client 3...\n  Client 3 Epoch 15: Loss=0.3656, Acc=85.21%\nValidating Client 3 locally...\n  Client 3 Local Val: Loss=0.3944, Acc=81.75%, F1=0.8541\nTraining Client 4...\n  Client 4 Epoch 15: Loss=0.1256, Acc=97.98%\nValidating Client 4 locally...\n  Client 4 Local Val: Loss=0.4992, Acc=77.55%, F1=0.7873\n\nAggregating client updates (simple averaging)...\n\nRound 8 Summary:\n  Avg Local Val Loss: 0.4454\n  Avg Local Val Acc:  79.34%\n  Avg Local Val F1:   0.8159\n\n============================================================\nROUND 9/15\n============================================================\nTraining Client 0...\n  Client 0 Epoch 15: Loss=0.0944, Acc=98.48%\nValidating Client 0 locally...\n  Client 0 Local Val: Loss=0.4637, Acc=78.82%, F1=0.7956\nTraining Client 1...\n  Client 1 Epoch 15: Loss=0.3663, Acc=85.87%\nValidating Client 1 locally...\n  Client 1 Local Val: Loss=0.5879, Acc=72.96%, F1=0.7641\nTraining Client 2...\n  Client 2 Epoch 15: Loss=0.0663, Acc=99.45%\nValidating Client 2 locally...\n  Client 2 Local Val: Loss=0.3413, Acc=85.49%, F1=0.8651\nTraining Client 3...\n  Client 3 Epoch 15: Loss=0.3569, Acc=85.42%\nValidating Client 3 locally...\n  Client 3 Local Val: Loss=0.4100, Acc=80.27%, F1=0.8419\nTraining Client 4...\n  Client 4 Epoch 15: Loss=0.1140, Acc=97.98%\nValidating Client 4 locally...\n  Client 4 Local Val: Loss=0.4771, Acc=76.85%, F1=0.7810\n\nAggregating client updates (simple averaging)...\n\nRound 9 Summary:\n  Avg Local Val Loss: 0.4560\n  Avg Local Val Acc:  78.88%\n  Avg Local Val F1:   0.8095\n\n============================================================\nROUND 10/15\n============================================================\nTraining Client 0...\n  Client 0 Epoch 15: Loss=0.0982, Acc=98.21%\nValidating Client 0 locally...\n  Client 0 Local Val: Loss=0.4464, Acc=79.96%, F1=0.8148\nTraining Client 1...\n  Client 1 Epoch 15: Loss=0.3555, Acc=87.43%\nValidating Client 1 locally...\n  Client 1 Local Val: Loss=0.6047, Acc=71.74%, F1=0.7507\nTraining Client 2...\n  Client 2 Epoch 15: Loss=0.0637, Acc=99.33%\nValidating Client 2 locally...\n  Client 2 Local Val: Loss=0.3501, Acc=84.44%, F1=0.8571\nTraining Client 3...\n  Client 3 Epoch 15: Loss=0.3439, Acc=87.01%\nValidating Client 3 locally...\n  Client 3 Local Val: Loss=0.3841, Acc=81.01%, F1=0.8447\nTraining Client 4...\n  Client 4 Epoch 15: Loss=0.1066, Acc=97.92%\nValidating Client 4 locally...\n  Client 4 Local Val: Loss=0.4633, Acc=78.52%, F1=0.7974\n\nAggregating client updates (simple averaging)...\n\nRound 10 Summary:\n  Avg Local Val Loss: 0.4497\n  Avg Local Val Acc:  79.13%\n  Avg Local Val F1:   0.8129\n\n============================================================\nROUND 11/15\n============================================================\nTraining Client 0...\n  Client 0 Epoch 15: Loss=0.0920, Acc=98.39%\nValidating Client 0 locally...\n  Client 0 Local Val: Loss=0.4702, Acc=79.96%, F1=0.8211\nTraining Client 1...\n  Client 1 Epoch 15: Loss=0.3543, Acc=86.51%\nValidating Client 1 locally...\n  Client 1 Local Val: Loss=0.5983, Acc=70.66%, F1=0.7429\nTraining Client 2...\n  Client 2 Epoch 15: Loss=0.0660, Acc=99.20%\nValidating Client 2 locally...\n  Client 2 Local Val: Loss=0.3457, Acc=84.71%, F1=0.8615\nTraining Client 3...\n  Client 3 Epoch 15: Loss=0.3781, Acc=84.24%\nValidating Client 3 locally...\n  Client 3 Local Val: Loss=0.3701, Acc=81.60%, F1=0.8495\nTraining Client 4...\n  Client 4 Epoch 15: Loss=0.0920, Acc=98.76%\nValidating Client 4 locally...\n  Client 4 Local Val: Loss=0.4876, Acc=79.08%, F1=0.8031\n\nAggregating client updates (simple averaging)...\n\nRound 11 Summary:\n  Avg Local Val Loss: 0.4544\n  Avg Local Val Acc:  79.20%\n  Avg Local Val F1:   0.8157\n\n============================================================\nROUND 12/15\n============================================================\nTraining Client 0...\n  Client 0 Epoch 15: Loss=0.0731, Acc=98.93%\nValidating Client 0 locally...\n  Client 0 Local Val: Loss=0.4584, Acc=80.15%, F1=0.8060\nTraining Client 1...\n  Client 1 Epoch 15: Loss=0.3170, Acc=88.64%\nValidating Client 1 locally...\n  Client 1 Local Val: Loss=0.5960, Acc=72.66%, F1=0.7620\nTraining Client 2...\n  Client 2 Epoch 15: Loss=0.0542, Acc=99.39%\nValidating Client 2 locally...\n  Client 2 Local Val: Loss=0.3420, Acc=84.58%, F1=0.8595\nTraining Client 3...\n  Client 3 Epoch 15: Loss=0.3315, Acc=87.01%\nValidating Client 3 locally...\n  Client 3 Local Val: Loss=0.3989, Acc=80.86%, F1=0.8455\nTraining Client 4...\n  Client 4 Epoch 15: Loss=0.0783, Acc=99.02%\nValidating Client 4 locally...\n  Client 4 Local Val: Loss=0.4751, Acc=78.52%, F1=0.7908\n\nAggregating client updates (simple averaging)...\n\nRound 12 Summary:\n  Avg Local Val Loss: 0.4541\n  Avg Local Val Acc:  79.35%\n  Avg Local Val F1:   0.8128\n\n============================================================\nROUND 13/15\n============================================================\nTraining Client 0...\n  Client 0 Epoch 15: Loss=0.0649, Acc=98.75%\nValidating Client 0 locally...\n  Client 0 Local Val: Loss=0.4694, Acc=80.15%, F1=0.8143\nTraining Client 1...\n  Client 1 Epoch 15: Loss=0.3119, Acc=89.06%\nValidating Client 1 locally...\n  Client 1 Local Val: Loss=0.5673, Acc=73.12%, F1=0.7765\nTraining Client 2...\n  Client 2 Epoch 15: Loss=0.0487, Acc=99.45%\nValidating Client 2 locally...\n  Client 2 Local Val: Loss=0.3114, Acc=85.88%, F1=0.8699\nTraining Client 3...\n  Client 3 Epoch 15: Loss=0.3519, Acc=87.22%\nValidating Client 3 locally...\n  Client 3 Local Val: Loss=0.3785, Acc=81.60%, F1=0.8477\nTraining Client 4...\n  Client 4 Epoch 15: Loss=0.0800, Acc=99.09%\nValidating Client 4 locally...\n  Client 4 Local Val: Loss=0.4759, Acc=78.38%, F1=0.7947\n\nAggregating client updates (simple averaging)...\n\nRound 13 Summary:\n  Avg Local Val Loss: 0.4405\n  Avg Local Val Acc:  79.83%\n  Avg Local Val F1:   0.8206\n\n============================================================\nROUND 14/15\n============================================================\nTraining Client 0...\n  Client 0 Epoch 15: Loss=0.0599, Acc=98.84%\nValidating Client 0 locally...\n  Client 0 Local Val: Loss=0.4837, Acc=80.53%, F1=0.8111\nTraining Client 1...\n  Client 1 Epoch 15: Loss=0.3107, Acc=88.71%\nValidating Client 1 locally...\n  Client 1 Local Val: Loss=0.5754, Acc=73.43%, F1=0.7785\nTraining Client 2...\n  Client 2 Epoch 15: Loss=0.0414, Acc=99.88%\nValidating Client 2 locally...\n  Client 2 Local Val: Loss=0.3168, Acc=85.88%, F1=0.8689\nTraining Client 3...\n  Client 3 Epoch 15: Loss=0.3438, Acc=86.53%\nValidating Client 3 locally...\n  Client 3 Local Val: Loss=0.3882, Acc=81.90%, F1=0.8537\nTraining Client 4...\n  Client 4 Epoch 15: Loss=0.0744, Acc=99.15%\nValidating Client 4 locally...\n  Client 4 Local Val: Loss=0.5299, Acc=77.27%, F1=0.7960\n\nAggregating client updates (simple averaging)...\n\nRound 14 Summary:\n  Avg Local Val Loss: 0.4588\n  Avg Local Val Acc:  79.80%\n  Avg Local Val F1:   0.8216\n\n============================================================\nROUND 15/15\n============================================================\nTraining Client 0...\n  Client 0 Epoch 15: Loss=0.0555, Acc=99.55%\nValidating Client 0 locally...\n  Client 0 Local Val: Loss=0.4687, Acc=80.73%, F1=0.8160\nTraining Client 1...\n  Client 1 Epoch 15: Loss=0.2936, Acc=89.91%\nValidating Client 1 locally...\n  Client 1 Local Val: Loss=0.6143, Acc=72.66%, F1=0.7627\nTraining Client 2...\n  Client 2 Epoch 15: Loss=0.0442, Acc=99.51%\nValidating Client 2 locally...\n  Client 2 Local Val: Loss=0.3077, Acc=86.67%, F1=0.8800\nTraining Client 3...\n  Client 3 Epoch 15: Loss=0.3194, Acc=88.47%\nValidating Client 3 locally...\n  Client 3 Local Val: Loss=0.3714, Acc=83.23%, F1=0.8589\nTraining Client 4...\n  Client 4 Epoch 15: Loss=0.0665, Acc=99.35%\nValidating Client 4 locally...\n  Client 4 Local Val: Loss=0.5126, Acc=78.10%, F1=0.7958\n\nAggregating client updates (simple averaging)...\n\nRound 15 Summary:\n  Avg Local Val Loss: 0.4549\n  Avg Local Val Acc:  80.28%\n  Avg Local Val F1:   0.8227\n\n================================================================================\nFEDERATED LEARNING TRAINING COMPLETE\n================================================================================\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"# Save the final global model\ntorch.save(global_model.state_dict(), 'simple_cnn_fedprox_baseline.pt')\nprint(\"Final global model saved as 'simple_cnn_fedprox_baseline.pt'\")\n\n# --- Training Progress Report ---\nprint(\"\\n\" + \"=\"*80)\nprint(\"TRAINING PROGRESS SUMMARY (Local Validation Only)\")\nprint(\"=\"*80)\n\n# Print final local validation metrics for each client\nprint(f\"\\nFinal Local Validation (Round {GLOBAL_ROUNDS}):\")\nfor client_id in range(clients):\n    final_acc = local_val_accs[client_id][-1]\n    final_f1 = local_val_f1s[client_id][-1]\n    print(f\"  Client {client_id}: Acc={final_acc:.2%}, F1={final_f1:.4f}\")\n\n# Print average local validation progress\nprint(f\"\\nAverage Local Validation Across Rounds:\")\nprint(f\"  Accuracy progression: {[f'{acc:.2%}' for acc in avg_local_val_accs]}\")\nprint(f\"  F1 Score progression: {[f'{f1:.4f}' for f1 in avg_local_val_f1s]}\")\n\n# Find best round based on average local F1\nbest_round = np.argmax(avg_local_val_f1s)\nprint(f\"\\nBest Round (based on avg local F1):\")\nprint(f\"  Round {best_round + 1}: Acc={avg_local_val_accs[best_round]:.2%}, F1={avg_local_val_f1s[best_round]:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:40:38.151664Z","iopub.execute_input":"2025-12-03T20:40:38.151994Z","iopub.status.idle":"2025-12-03T20:40:38.232849Z","shell.execute_reply.started":"2025-12-03T20:40:38.151966Z","shell.execute_reply":"2025-12-03T20:40:38.232243Z"}},"outputs":[{"name":"stdout","text":"Final global model saved as 'simple_cnn_fedprox_baseline.pt'\n\n================================================================================\nTRAINING PROGRESS SUMMARY (Local Validation Only)\n================================================================================\n\nFinal Local Validation (Round 15):\n  Client 0: Acc=80.73%, F1=0.8160\n  Client 1: Acc=72.66%, F1=0.7627\n  Client 2: Acc=86.67%, F1=0.8800\n  Client 3: Acc=83.23%, F1=0.8589\n  Client 4: Acc=78.10%, F1=0.7958\n\nAverage Local Validation Across Rounds:\n  Accuracy progression: ['73.10%', '74.06%', '76.75%', '76.98%', '78.35%', '77.95%', '78.64%', '79.34%', '78.88%', '79.13%', '79.20%', '79.35%', '79.83%', '79.80%', '80.28%']\n  F1 Score progression: ['0.7442', '0.7627', '0.7909', '0.7941', '0.8037', '0.7995', '0.8113', '0.8159', '0.8095', '0.8129', '0.8157', '0.8128', '0.8206', '0.8216', '0.8227']\n\nBest Round (based on avg local F1):\n  Round 15: Acc=80.28%, F1=0.8227\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":"# **VALIDATION**","metadata":{}},{"cell_type":"code","source":"# --- Create Test DataLoader ---\ndef create_test_dataloader(global_test_df, batch_size=64, num_workers=4):\n    \"\"\"Create DataLoader for global test set\"\"\"\n    \n    test_dataset = XRayDataset(\n        df=global_test_df,\n        transform=val_transforms\n    )\n    \n    test_loader = DataLoader(\n        test_dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=num_workers,\n        pin_memory=True\n    )\n    \n    print(f\"Global test dataloader created: {len(test_dataset)} samples\")\n    return test_loader\n\nglobal_test_loader = create_test_dataloader(global_test_df, batch_size=64)\n\n\n# --- Comprehensive Global Evaluation ---\ndef evaluate_global_model(model, test_loader, device=DEVICE):\n    \"\"\"\n    Comprehensive evaluation of the global model\n    Returns detailed metrics including confusion matrix\n    \"\"\"\n    from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n    import numpy as np\n    \n    model.eval()\n    model.to(device)\n    \n    all_preds = []\n    all_probs = []\n    all_labels = []\n    total_loss = 0.0\n    \n    print(f\"\\n{'='*80}\")\n    print(\"GLOBAL MODEL EVALUATION\")\n    print(f\"{'='*80}\")\n    \n    with torch.no_grad():\n        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n            images = images.to(device)\n            labels = labels.to(device).float()\n            \n            # Forward pass\n            logits = model(images)\n            probs = torch.sigmoid(logits)\n            preds = (probs > 0.475).long()\n            \n            # Loss\n            loss = criterion(logits, labels)\n            total_loss += loss.item() * images.size(0)\n            \n            # Collect predictions\n            all_preds.extend(preds.cpu().tolist())\n            all_probs.extend(probs.cpu().tolist())\n            all_labels.extend(labels.long().cpu().tolist())\n    \n    # Convert to numpy\n    all_preds = np.array(all_preds)\n    all_probs = np.array(all_probs)\n    all_labels = np.array(all_labels)\n    \n    # Calculate metrics\n    avg_loss = total_loss / len(test_loader.dataset)\n    accuracy = (all_preds == all_labels).mean()\n    \n    # Confusion matrix\n    cm = confusion_matrix(all_labels, all_preds)\n    tn, fp, fn, tp = cm.ravel()\n    \n    # Precision, Recall, F1\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n    \n    # Specificity (True Negative Rate)\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n    \n    # Balanced Accuracy\n    balanced_acc = (recall + specificity) / 2\n    \n    # AUC-ROC\n    try:\n        auc_roc = roc_auc_score(all_labels, all_probs)\n    except:\n        auc_roc = 0.0\n    \n    # Print results\n    print(f\"\\n{'─'*80}\")\n    print(\"OVERALL METRICS\")\n    print(f\"{'─'*80}\")\n    print(f\"Loss:              {avg_loss:.4f}\")\n    print(f\"Accuracy:          {accuracy:.4f} ({accuracy*100:.2f}%)\")\n    print(f\"Balanced Accuracy: {balanced_acc:.4f} ({balanced_acc*100:.2f}%)\")\n    print(f\"AUC-ROC:           {auc_roc:.4f}\")\n    \n    print(f\"\\n{'─'*80}\")\n    print(\"PER-CLASS METRICS\")\n    print(f\"{'─'*80}\")\n    print(f\"Precision:         {precision:.4f}\")\n    print(f\"Recall/Sensitivity:{recall:.4f}\")\n    print(f\"Specificity:       {specificity:.4f}\")\n    print(f\"F1-Score:          {f1:.4f}\")\n    \n    print(f\"\\n{'─'*80}\")\n    print(\"CONFUSION MATRIX\")\n    print(f\"{'─'*80}\")\n    print(f\"                Predicted\")\n    print(f\"              Normal  Pneumonia\")\n    print(f\"Actual Normal    {tn:>4}     {fp:>4}\")\n    print(f\"    Pneumonia    {fn:>4}     {tp:>4}\")\n    \n    print(f\"\\n{'─'*80}\")\n    print(\"INTERPRETATION\")\n    print(f\"{'─'*80}\")\n    print(f\"True Negatives:  {tn} (correctly predicted normal)\")\n    print(f\"False Positives: {fp} (normal predicted as pneumonia)\")\n    print(f\"False Negatives: {fn} (pneumonia predicted as normal)\")\n    print(f\"True Positives:  {tp} (correctly predicted pneumonia)\")\n    \n    # Clinical interpretation\n    print(f\"\\n{'─'*80}\")\n    print(\"CLINICAL METRICS\")\n    print(f\"{'─'*80}\")\n    ppv = tp / (tp + fp) if (tp + fp) > 0 else 0  # Positive Predictive Value\n    npv = tn / (tn + fn) if (tn + fn) > 0 else 0  # Negative Predictive Value\n    print(f\"PPV (Precision):   {ppv:.4f} - When model says pneumonia, it's right {ppv*100:.1f}% of time\")\n    print(f\"NPV:               {npv:.4f} - When model says normal, it's right {npv*100:.1f}% of time\")\n    print(f\"Sensitivity:       {recall:.4f} - Detects {recall*100:.1f}% of actual pneumonia cases\")\n    print(f\"Specificity:       {specificity:.4f} - Correctly identifies {specificity*100:.1f}% of normal cases\")\n    \n    print(f\"{'='*80}\\n\")\n    \n    # Return metrics dict\n    metrics = {\n        'loss': avg_loss,\n        'accuracy': accuracy,\n        'balanced_accuracy': balanced_acc,\n        'precision': precision,\n        'recall': recall,\n        'specificity': specificity,\n        'f1': f1,\n        'auc_roc': auc_roc,\n        'confusion_matrix': cm,\n        'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn\n    }\n    \n    return metrics","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:42:20.673297Z","iopub.execute_input":"2025-12-03T20:42:20.673827Z","iopub.status.idle":"2025-12-03T20:42:20.695568Z","shell.execute_reply.started":"2025-12-03T20:42:20.673804Z","shell.execute_reply":"2025-12-03T20:42:20.694879Z"}},"outputs":[{"name":"stdout","text":"Global test dataloader created: 6329 samples\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"# Evaluate the final model\nprint(\"\\n\" + \"=\"*80)\nprint(\"EVALUATING FINAL GLOBAL MODEL\")\nprint(\"=\"*80 + \"\\n\")\n\nmetrics = evaluate_global_model(global_model, global_test_loader, device=DEVICE)\n\n# Print summary\nprint(f\"\\nFINAL RESULTS SUMMARY:\")\nprint(f\"   Accuracy: {metrics['accuracy']:.2%}\")\nprint(f\"   F1-Score: {metrics['f1']:.4f}\")\nprint(f\"   AUC-ROC:  {metrics['auc_roc']:.4f}\")\nprint(f\"   Sensitivity: {metrics['recall']:.4f}\")\nprint(f\"   Specificity: {metrics['specificity']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T20:42:25.059860Z","iopub.execute_input":"2025-12-03T20:42:25.060405Z","iopub.status.idle":"2025-12-03T20:42:47.753176Z","shell.execute_reply.started":"2025-12-03T20:42:25.060382Z","shell.execute_reply":"2025-12-03T20:42:47.752265Z"}},"outputs":[{"name":"stdout","text":"\n================================================================================\nEVALUATING FINAL GLOBAL MODEL\n================================================================================\n\n\n================================================================================\nGLOBAL MODEL EVALUATION\n================================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b58062168df643c4a1af64674da9ba60"}},"metadata":{}},{"name":"stdout","text":"\n────────────────────────────────────────────────────────────────────────────────\nOVERALL METRICS\n────────────────────────────────────────────────────────────────────────────────\nLoss:              0.7755\nAccuracy:          0.6232 (62.32%)\nBalanced Accuracy: 0.6629 (66.29%)\nAUC-ROC:           0.7858\n\n────────────────────────────────────────────────────────────────────────────────\nPER-CLASS METRICS\n────────────────────────────────────────────────────────────────────────────────\nPrecision:         0.4890\nRecall/Sensitivity:0.8083\nSpecificity:       0.5174\nF1-Score:          0.6093\n\n────────────────────────────────────────────────────────────────────────────────\nCONFUSION MATRIX\n────────────────────────────────────────────────────────────────────────────────\n                Predicted\n              Normal  Pneumonia\nActual Normal    2084     1944\n    Pneumonia     441     1860\n\n────────────────────────────────────────────────────────────────────────────────\nINTERPRETATION\n────────────────────────────────────────────────────────────────────────────────\nTrue Negatives:  2084 (correctly predicted normal)\nFalse Positives: 1944 (normal predicted as pneumonia)\nFalse Negatives: 441 (pneumonia predicted as normal)\nTrue Positives:  1860 (correctly predicted pneumonia)\n\n────────────────────────────────────────────────────────────────────────────────\nCLINICAL METRICS\n────────────────────────────────────────────────────────────────────────────────\nPPV (Precision):   0.4890 - When model says pneumonia, it's right 48.9% of time\nNPV:               0.8253 - When model says normal, it's right 82.5% of time\nSensitivity:       0.8083 - Detects 80.8% of actual pneumonia cases\nSpecificity:       0.5174 - Correctly identifies 51.7% of normal cases\n================================================================================\n\n\nFINAL RESULTS SUMMARY:\n   Accuracy: 62.32%\n   F1-Score: 0.6093\n   AUC-ROC:  0.7858\n   Sensitivity: 0.8083\n   Specificity: 0.5174\n","output_type":"stream"}],"execution_count":48}]}