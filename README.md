Federated Learning has made training of medical AI models across multiple institutions more secure without sharing patientsâ€™ sensitive information. Nevertheless, two major issues occurring in the real-world clinical situations are label scarcity in datasets and non-Independent and Identically Distributed (nonIID) data distributions. To address these issues, we have proposed a new FL framework incorporating self-supervised learning (SSL) with client-sensitive aggregation scheme beneficial for challenges like pneumonia detection using chest X-ray images. This framework uses MAE and BEiT as masked image modeling models (MIM) for the federated SSL pre-training on unlabeled data, and then FedProx along with loss-weighted aggregation to minimize client drift and fairly access global model updates. It has been shown through the experimental validation on publicly available datasets of chest X-rays that the proposed work enhances overall model generalization, better accuracy in scarce label setting and non-IID data and also reduces the variability of its performance with diverse clients. Moreover, the architecture ensures privacy is preserved by preventing any sharing of raw embeddings, making it suitable in real-world medical FL applications.
